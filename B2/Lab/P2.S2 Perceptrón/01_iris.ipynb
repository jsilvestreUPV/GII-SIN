{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrón aplicado a iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lectura del corpus:** $\\;$ cargamos el corpus Iris y comprobamos que las matrices de datos `X` y etiquetas `y` contienen el número de filas y columnas que esperamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150, 1) \n",
      " [[5.1015625  3.5        1.40039062 0.19995117 0.        ]\n",
      " [4.8984375  3.         1.40039062 0.19995117 0.        ]\n",
      " [4.69921875 3.19921875 1.29980469 0.19995117 0.        ]\n",
      " [4.6015625  3.09960938 1.5        0.19995117 0.        ]\n",
      " [5.         3.59960938 1.40039062 0.19995117 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np;\n",
    "from sklearn.datasets import load_iris;\n",
    "iris = load_iris(); \n",
    "X = iris.data.astype(np.float16);\n",
    "y = iris.target.astype(np.uint).reshape(-1, 1);\n",
    "print(X.shape, y.shape, \"\\n\", np.hstack([X, y])[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Partición del corpus:** $\\;$ Creamos un split del dataset iris con un $20\\%$ de datos (30 muestras) para evaluación (*test*), y el resto (120 muestras) para entrenamiento (*training*), barajando previamente los datos de acuerdo con una semilla dada para la generación de números aleatorios. Aquí, como en todo código que incluya aleatoriedad (que requiera generar números aleatorios), conviene fijar dicha semilla para poder reproducir experimentos posteriormente con exactitud. En este caso, usaremos como semilla un objeto `int` con valor 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "       train_test_split(X, y, test_size=0.2, \n",
    "                        shuffle=True, \n",
    "                        random_state=23)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementación de Perceptrón:** $\\;$ aplica el algoritmo de aprendizaje perceptrón, partiendo de pesos $\\mathbf{W}$ nulos. \n",
    "\n",
    "Recibe como parámetros de entrada:\n",
    "\n",
    "- Matriz de muestras de entrenamiento `X`,\n",
    "- Vector de etiquetas de clase `y`,\n",
    "- Valores de los hiperparámetros del algoritmo (a optimizar de manera experimental):\n",
    "    - Variable de margen `b` $\\ge 0$,\n",
    "    - Factor de aprendizaje `a` $> 0$,\n",
    "    - Número máximo de iteraciones `K` $> 0$. \n",
    "\n",
    "Devuelve:\n",
    "\n",
    "- Pesos optimizados `W`, en notación homogénea, $\\mathbf{W}\\in\\mathbb{R}^{(1+D)\\times C}\\;$,  \n",
    "- Número de muestras de train incorrectamente clasificadas `E` durante la última iteración realizada,\n",
    "- Número de iteraciones ejecutadas `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(X, y, b=0.1, a=1.0, K=200):\n",
    "    N, D = X.shape; \n",
    "    Y = np.unique(y); \n",
    "    C = Y.size; \n",
    "    W = np.zeros((1+D, C));\n",
    "    for k in range(1, K+1):\n",
    "        E = 0\n",
    "        for n in range(N):\n",
    "            xn = np.array([1, *X[n, :]]);\n",
    "            cn = np.squeeze(np.where(Y==y[n]));\n",
    "            gn = W[:,cn].T @ xn; \n",
    "            err = False;\n",
    "            for c in np.arange(C):\n",
    "                if c != cn and W[:,c].T @ xn + b >= gn:\n",
    "                    W[:, c] = W[:, c] - a*xn; \n",
    "                    err = True;\n",
    "            if err:\n",
    "                W[:, cn] = W[:, cn] + a*xn; \n",
    "                E = E + 1;\n",
    "        if E == 0:\n",
    "            break;\n",
    "    return W, E, k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aprendizaje de un clasificador (lineal) con Perceptrón:** $\\;$ Perceptrón minimiza el número de errores de entrenamiento (con margen `b`)\n",
    "$$\\mathbf{W}^*=\\operatorname*{argmin}_{\\mathbf{W}=(\\boldsymbol{w}_1,\\dotsc,\\boldsymbol{w}_C)}\\sum_n\\;\\mathbb{Y}\\biggl(\\max_{c\\neq y_n}\\;\\boldsymbol{w}_c^t\\boldsymbol{x}_n+b \\;>\\; \\boldsymbol{w}_{y_n}^t\\boldsymbol{x}_n\\biggr)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de iteraciones ejecutadas:  200\n",
      "Número de errores de entrenamiento durante la última iteración:  2\n",
      "Vectores de pesos de las clases (en columnas y en notación homogénea):\n",
      " [[  10.           85.         -142.        ]\n",
      " [ -49.421875    -68.19140625 -176.47265625]\n",
      " [  50.171875     -1.72460938 -181.06445312]\n",
      " [-189.91210938  -87.70507812   68.69726562]\n",
      " [ -86.40258789 -137.78149414  157.88415527]]\n"
     ]
    }
   ],
   "source": [
    "W, E, k = perceptron(X_train, y_train);\n",
    "print(\"Número de iteraciones ejecutadas: \", k);\n",
    "print(\"Número de errores de entrenamiento durante la última iteración: \", E);\n",
    "print(\"Vectores de pesos de las clases (en columnas y en notación homogénea):\\n\", W);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de la tasa de error en test:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de error en test: 16.7%\n"
     ]
    }
   ],
   "source": [
    "X_testh = np.hstack([np.ones((len(X_test), 1)), X_test])\n",
    "y_test_pred  = np.argmax(X_testh @ W, axis=1).reshape(-1, 1)\n",
    "err_test = np.count_nonzero(y_test_pred != y_test) / len(X_test)\n",
    "print(f\"Tasa de error en test: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de resultados:** $\\;$ los datos de entrenamiento no parecen linealmente separables; con margen $b=0.1$ se obtiene un error de clasificación en test del $16.7\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ajuste del margen:** $\\;$ experimento para optimizar el valor del hiperparámetro $b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#      b\t E\t   k\n",
      "    0.00\t 3\t1000\n",
      "    0.01\t 5\t1000\n",
      "    0.10\t 3\t1000\n",
      "   10.00\t 6\t1000\n",
      "  100.00\t 6\t1000\n"
     ]
    }
   ],
   "source": [
    "print(\"# {:>6s}\\t{:>2s}\\t{:>4s}\".format(\"b\", \"E\", \"k\"));\n",
    "for b in (.0, .01, .1, 10, 100):\n",
    "    W, E, k = perceptron(X_train, y_train, b=b, K=1000)\n",
    "    print(\"  {:6.2f}\\t{:>2d}\\t{:>4d}\".format(b, E, k));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viendo esta tabla (número de errores en entrenamiento durante la última iteración del algoritmo perceptrón en función de `b`) resulta dificil extraer conclusiones. Deberíamos evaluar la tasa de error en test para determinar el valor de `b` óptimo (que permite generalizar mejor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**: modifica la celda de código anterior para que calcule la tasa de error en test para cada experimento y lo muestre en la tabla en una nueva columna. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sin-2324",
   "language": "python",
   "name": "sin-2324"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

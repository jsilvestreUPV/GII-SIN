{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión logística aplicada al corpus y tarea Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lectura del corpus y partición:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lectura/carga del corpus\n",
    "iris = load_iris()\n",
    "X = iris.data.astype(np.float16) # muestras\n",
    "y = iris.target.astype(np.uint)  # etiquetas de clase\n",
    "\n",
    "# Partición (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regresión logística\n",
    "\n",
    "Usamos la implementación de regresión logística (clase [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)) de la librería [sklearn](https://scikit-learn.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test: 6.7%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Código para filtrar los (molestos) warnings de sklearn sobre convergencia\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"sklearn\")\n",
    "\n",
    "# entrenamiento \n",
    "model = LogisticRegression(random_state=22).fit(X_train, y_train)\n",
    "\n",
    "# clasificación (test)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# cálculo tasa de error de test\n",
    "err_test = 1 - accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Error de test: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ajuste de hiperparámetros\n",
    "\n",
    "A continuación se describen algunos hiperparámetros del [método constructor `LogisticRegression()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) que pueden ser ajustados experimentalmente para minimzar la tasa de error en test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Algoritmo de optimización\n",
    "\n",
    "El parámetro `solver` permite elegir entre [6 algoritmos de optimitzación diferentes](https://scikit-learn.org/stable/modules/linear_model.html#solvers). No vamos a entrar en detalles sobre sus características y funcionamiento, pero es un parámetro que podemos explorar de manera experimental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test después de entrenar con el solver lbfgs: 6.7%\n",
      "Error de test después de entrenar con el solver liblinear: 3.3%\n",
      "Error de test después de entrenar con el solver newton-cg: 6.7%\n",
      "Error de test después de entrenar con el solver newton-cholesky: 3.3%\n",
      "Error de test después de entrenar con el solver sag: 0.0%\n",
      "Error de test después de entrenar con el solver saga: 0.0%\n"
     ]
    }
   ],
   "source": [
    "for solver in ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']:\n",
    "    model = LogisticRegression(random_state=22, solver=solver).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"Error de test después de entrenar con el solver {solver!s}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Tolerancia\n",
    "\n",
    "El parámetro `tol` establece el umbral de tolerancia mínimo necesario para continuar el entrenamiento (`1e-4` por defecto). Si la tolerancia es inferior a dicho umbral, el entrenamiento finaliza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test con tolerancia 0.0001: 6.7%\n",
      "Error de test con tolerancia 0.01: 6.7%\n",
      "Error de test con tolerancia 1: 3.3%\n",
      "Error de test con tolerancia 100.0: 80.0%\n",
      "Error de test con tolerancia 10000.0: 80.0%\n"
     ]
    }
   ],
   "source": [
    "for tol in (1e-4, 1e-2, 1, 1e2, 1e4):\n",
    "    model = LogisticRegression(tol=tol, random_state=22).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"Error de test con tolerancia {tol}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Regularización\n",
    "\n",
    "`LogisticRegression` añade por defecto una [regularización del criterio de entrenamiento basada en la norma $\\ell_2$](https://scikit-learn.org/stable/modules/linear_model.html#multinomial-case). El propósito de esta regularización es evitar un sobre-ajuste del modelo a los datos de entrenamiento, apostando por unos parámetros más sencillos (más próximos a cero). El parámetro `C` (positivo, $1.0$ por defecto) permite ajustar a la inversa la magnitud de dicha regularización:\n",
    "* **Máxima regularización** (sub-ajuste): $\\;$ con un valor de `C` próximo a cero.\n",
    "* **Mínima regularización** (sobre-ajuste): $\\;$ con un valor positivo muy alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test con C 0.001: 46.7%\n",
      "Error de test con C 0.01: 10.0%\n",
      "Error de test con C 0.1: 10.0%\n",
      "Error de test con C 1: 6.7%\n",
      "Error de test con C 10: 0.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test con C 100: 3.3%\n"
     ]
    }
   ],
   "source": [
    "for C in (1e-3, 1e-2, 1e-1, 1, 1e1, 1e2):\n",
    "    model = LogisticRegression(C=C, random_state=22).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"Error de test con C {C:g}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Número de iteraciones máximas\n",
    "\n",
    "El parámetro `max_iter` ($100$ por defecto) permite ajustar el número total de iteraciones del algoritmo de optimización. Ajustaremos este número basándonos en el criterio *Early stopping*: detenemos el entrenamiento lo más pronto posible (en pocas iteraciones) para evitar un sobre-entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de test con max_iter 10: 6.7%\n",
      "Error de test con max_iter 20: 3.3%\n",
      "Error de test con max_iter 50: 10.0%\n",
      "Error de test con max_iter 100: 6.7%\n"
     ]
    }
   ],
   "source": [
    "for max_iter in (10, 20, 50, 100):\n",
    "    model = LogisticRegression(random_state=22, max_iter=max_iter).fit(X_train, y_train)\n",
    "    err_test = 1 - accuracy_score(y_test, model.predict(X_test))\n",
    "    print(f\"Error de test con max_iter {max_iter}: {err_test:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ejercicio\n",
    "\n",
    "Realiza una exploración combinada de diferentes hiperparámetros, calculando las tasas de error en train y test para cada experimento, mostrándolas en una tabla de resultados (similar a la del [cuaderno del Perceptrón](../P2.S2%20Perceptrón/01_iris.ipynb)). A partir de esta información, determina los valores óptimos de los hiperparámetros. Recuerda que, como regla general, **seleccionaremos el conjunto de valores de hiperparámeros que minimicen la tasa de error en test**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sin-2324",
   "language": "python",
   "name": "sin-2324"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
